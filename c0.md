> 此份笔记是个人看书总结见解，如有错误不合理之处可以提出

# 前言

p11如何规划学时

ch1 3h

ch2 2h

ch3 4h

# 引言

由潜意识引出什么是人工智能，从人工与智能分开思考

评估智能可以通过问答的间接方式，感觉类似于chatgpt形式

接着具体介绍图灵测试以及相关争议，有人认为测试存在“背答案”，“不会但写出了答案”的漏洞

顺带介绍了艾伦图灵（Alan Turing）的人物轶事

# 强弱人工智能

Weak AI标准：程序能正确跑，看系统表现就行

Strong AI认为：跟人类相似表现，具有理解和从经验中学习的能力

# 启发式方法

解决问题的经验指导法则

举了两个例子：

- 有长方形对角线推出长方体的对角线

- 水壶倒水从目的状态反向倒推

# 识别适用人工智能来求解的问题

简单决策，精确计算用传统计算机就能解决

人工智能应用场景在几个例子上体现作用

# 应用和方法

知识与推理规则

构建智能系统提到了细胞自动机（CA）

接着讲人工智能研究领域应用，下面更多是提起概念，留在后面篇章去探讨细讲

## 搜索算法和拼图问题

 对给定问题的所有状态进行搜索

- 深度优先搜索（DFS）
- 广度优先搜索（BFS）

但很多问题不是穷举就能解决的，又探讨出启发式搜索方法，第三章深入再讲

## 二人博弈

不止专注于自己目标，也要去关注对方并行动

## 自动推理

场景问题较大且复杂难懂

## 产生式系统和专家系统

知识表示方法，感觉像是写普遍规则

## 细胞自动机

通过应用几个简单的规则，就可以创建出非常复杂的模式

两个额外性质：物理拓扑，更新规则

## 神经计算

通过几个输入与权值的处理结果再与阈值相计算，有点像激活函数

权重的得来是通过迭代学习算法（感知器学习规则）

## 遗传算法

遗传算法来自于进化计算的一般领域的具体方法，对接近目的的选择方案给更高的权重

## 知识表示

人工智能为了处理知识，需要获取和存储知识，也需要能够识别和表示知识

从逻辑谈到语义网络再到图的知识表示方法

## 不确定性推理

引入模糊集概念， 随条件变化而变化，有一个可接受的范围

# 人工智能的早期历史

走捷径，真【人工】智能

古代也有人发现人类推理的能力，这个小章节篇幅也是在介绍知名人物对理论与技术的推进，为人工智能演变打基础

# 近期历史到现在

- 计算机博弈--下棋发展，到现在大家都知道的alphago

- 专家系统 --特性适合ai的研发和开发，使用知识库和推理规则模仿人类专家决策能力解决领域特定问题

- 神经计算--感知器与反向传播算法

- 进化计算--优化以及与环境交互出现智能

- 自然语言处理--假装有感知情绪能力模拟心理治疗师，语法语义分析还需要常识补全

- 生物信息学--蛋白质结构分析，个人提一嘴现在的alphaold进步确实快

# 新千年人工智能的发展

各种存在的问题比如说道德伦理，有挑战需要做好思考准备

# 本章小结

## 讨论题

[参考答案](https://juejin.cn/post/7325242594653077540)

## 练习题

1.图灵测试的一种变体是逆图灵测试（inverted Turing test）；在这个测试中，计算机必须确定它是在与人打交道还是在与另一台计算机打交道。请想象一下这种版本的图灵测试可能的任何实际应用。（提示：近年来，大家试过在线购买热门体育或娱乐活动的门票吗？）

网络安全方面上，验证用户真实身份，识别异常行为并采取防御措施，保护用户权益防止信息泄露



2.图灵测试的另一种变体是个人图灵测试（personal Turing test）。想象一下，你试图确定与你交流的是你朋友还是一台假装是你朋友的计算机。如果计算机通过了这个测试，试想可能会产生什么法律或道德问题。

情感寄托方面：对方假装朋友最后有着情感交流寄托难以割舍，发现真相是否世界观崩溃

网络安全方面：对方假装朋友获取你私人信息并恶意使用，比如网络诈骗或者机密信息盗取



3.许多人认为语言的使用是智能的必要属性。Koko是一只大猩猩，她经过斯坦福大学的弗朗西斯·帕特森博士培训后会使用美国手语。Koko能够表达她不知道的单词组合。例如，她用已知的“手镯”和“手指”这样的词来表示戒指。这只“具备一定知识”的大猩猩是否改变了你对动物智能这个主题的思考？如果是，请回答在什么方面改变了？你能够想象给 Koko 来一次智力测试吗？

Koko这只大猩猩能够使用美国手语来表达她不知道的单词组合，这确实改变了我对动物智能这个主题的思考。以下是一些改变的方面：

在语言能力方面：Koko的例子表明动物可能具有一定程度的语言能力。这意味着它们不仅仅是被动地接受信息，而是能够主动地表达自己的想法和需求。这挑战了我们过去对动物智能的认识，即它们只能通过本能和条件反射来适应环境。

在认知能力方面：Koko能够将已知的词汇组合成新的概念，这表明她具有一定的认知能力。这意味着动物可能具有一定程度的抽象思维和问题解决能力。这进一步证明了动物智能的复杂性。

在教育潜力方面：Koko的例子表明，动物具有一定的教育潜力。这意味着可以通过训练和教育来提高动物的认知能力和技能，为我们提供了一个新的视角，即动物教育和保护的重要性。

插入一个打工人笑话：为什么猩猩进化到这样就不再进化了？因为他知道再进化就要上班了。🤣

关于给Koko进行智力测试的问题，我认为可以尝试以下几种方法：

词汇测试：可以设计一些词汇测试题，观察Koko是否能够正确地识别和使用手语词汇。

概念测试：可以设计一些概念测试题，观察Koko是否能够理解并运用已知词汇来表示新的概念。

问题解决测试：可以设计一些问题解决任务，观察Koko是否能够运用她的知识和技能来解决实际问题。

情感交流测试：可以通过观察Koko与人的互动，评估她在情感交流方面的能力。



4.假定通过如下测试的城市被认定为大城市。

- 它应该可能在凌晨 3:00 提供牛排餐。

- 每个夜晚，在城市范围内的某个地方都应该安排一场古典音乐会。

- 每个夜晚都应该安排一场重要的体育赛事。

假设美国的某个小镇上的居民想通过这个测试，他们为此开了一家 24 小时营业的牛排店，聘请了一支交响乐团并获得了大型体育特许经营权。那么大家觉得这个小镇能够通过上述大城市认定的测试吗？请将这个讨论与通过原始图灵测试和拥有智能的标准相关联（Dennett，2004）

条件都满足能通过，但通过这些测试并不一定意味着这个小镇就真正成为了一个大城市。大城市的定义不局限于提供特定服务的能力，还包括人口规模、经济活力、文化影响力等多个方面，满足这些测试条件并不能确定一个小镇是否真正具备大城市的特征。原始图灵测试旨在评估一个机器是否能够表现出与人类相似的智能行为。类似地，这个小镇通过提供牛排餐、举办音乐会和体育赛事来模拟大城市的特征。然而，就像图灵测试一样，仅仅满足某些特定的条件并不足以证明一个系统或实体真正具备智能。



5.假设要设计一个阈值逻辑单元（TLU）来模拟双输入的或（OR）函数，你能否确定一个阈值和所有权重来完成这一任务？

假设有两个输入x1和x2，以及一个阈值t。如果x1或x2大于或等于t，那么输出y就是1，否则输出y就是0。我们可以将每个输入乘以一个权重w，然后将结果相加。如果总和大于或等于阈值t，那么输出y就是1，否则输出y就是0。



6.考虑迭代囚徒困境游戏的一种策略：对于某个未知数 n，游戏重复 n 次。从长远来看， 如何衡量该策略是否成功？

制定一些衡量标准：

平均得分：在每次游戏中，玩家可以选择合作或背叛。如果两个玩家都选择合作，他们都会获得一个高得分（例如3分）。如果一个玩家选择合作，另一个玩家选择背叛，那么背叛的玩家会获得更高的得分（例如5分），而合作的玩家会获得较低的得分（例如1分）。如果两个玩家都选择背叛，他们都会得到较低的得分（例如0分）。在这种情况下，我们可以计算玩家在所有游戏中的平均得分，以衡量他们的总表现。

稳定性：在多次游戏中，玩家的策略是否稳定也是一个重要的考量因素。如果一个玩家的策略在不同的游戏环境中都能保持一致，那么我们可以说这个策略是稳定的。

与理论最优策略的比较：理论上，如果所有玩家都选择合作，他们将获得最高的得分。因此，我们也可以将玩家的实际得分与理论最优得分进行比较，以衡量他们的策略是否成功。



7.采用遗传算法来解决本章中提供的 3 拼图问题，建议使用字符串来表达可能的解。这里大家会建议使用什么适应度函数？

曼哈顿距离：计算拼图块与其目标位置之间的曼哈顿距离之和。曼哈顿距离是指在网格中从一个点到另一个点的最短路径长度，不考虑对角线移动。适应度值越小，说明解的质量越高。

逆序数：计算拼图块序列中逆序对的数量。逆序对是指两个相邻的拼图块在目标位置上的顺序错误，适应度值越小，说明解的质量越高。



8.给出一个启发式方法，使你能够在高峰时段出租车稀缺时，乘坐出租车访问纽约市（或任何其他主要城市）。

提前预约（这个真的深有体会，尤其是dd平台崩了那回）

考虑拼车（慎重选择，之前有过司机带着我的行李箱就走了还恶意不归还）

多平台下单，选择高价位服务

与同事或朋友一起拼车

骑共享单车中途遇到出租车下客的立马上去跟司机交流



9.狮子在追击猎物时，可能会使用什么启发式方法？

最近距离，落单弱小猎物



10.假设要设计一个专家系统，用于帮助家庭选择合适的狗，请建议一些可能的规则。

- 狗的大小：根据家庭的大小和空间选择合适大小的狗。例如对于小型公寓小型或中型狗可能更合适。

- 狗的活跃度：考虑家庭成员的活动水平和对运动的需求，如果家庭成员经常进行户外活动，可以选择一种活跃度高需要大量运动的狗。

- 狗的护理需求：不同的狗有不同的护理需求。有些狗需要每天梳理，有些狗需要定期洗澡，有些狗需要专业的美容。根据家庭的时间和能力，选择合适的狗。

- 狗的寿命：考虑狗的平均寿命和家庭成员是否愿意并能够承担长期的责任。一些狗的寿命比其他狗短，这可能会影响家庭成员的决定。

- 狗的性格：了解狗的性格和行为习惯，选择与家庭成员性格相匹配的狗。例如，一些狗非常友好，适合有小孩的家庭，而一些狗可能更适合独居者。

- 狗的健康问题：了解狗可能患有的健康问题，选择健康的狗种。一些狗种可能有遗传性疾病，这可能会增加医疗费用。

- 狗的食物需求：不同的狗有不同的食物需求。一些狗可能需要特殊的食物来满足其营养需求，这可能会增加家庭的经济负担。



11.在哥白尼之前，地球被认为是宇宙的中心。在哥白尼之后，人类明白了地球只是绕着太阳旋转的众多行星之一。在达尔文之前，人类认为自己是与这个行星中的其他生命有机体分离开来的物种（并且高于其他物种？）。在达尔文之后，人类明白了自己只是从单细胞生物演化而来的另一种动物。假设人类级别的人工智能在 50 年后已经实现，并且进一步假设机器人 Cog、 Paro 和 Kismet 的继承者实际上体验到了情绪，而不是假装有这样的情绪。在人类历史上的这样一个时刻，作为形成人类“特殊性”的核心，人类应该坚持什么主张？这些主张是不是必要的？ 抑或甚至是大家想要的吗？

坚持道德和伦理观念：人类拥有独特的道德和伦理观念，这使得我们能够区分对错，建立社会秩序，并关心他人的利益。这种道德观念使得人类能够在社会中共存共荣。

坚持文化传承和发展：人类拥有悠久的文化传承，包括语言、宗教、艺术、科学等各个方面。这些文化传统使得人类得以不断发展和进步，也为我们的生活增添了丰富的色彩。

坚持自由意志和选择权：人类拥有自由意志和选择权，这使得我们能够根据自己的意愿和价值观来塑造自己的生活。这种自由意志使得人类具有无限的创造力和潜能。

这些主张对于维护人类的尊严和价值具有重要意义，它们使我们与其他生物有所区别，也是人类社会得以持续发展的基础。在未来的社会我们也需要不断地审视和调整自己的观点，以确保人类的“特殊性”得到尊重和维护。



12.假设在将来的某一天，美国宇航局计划在木星的卫星 Europa 上进行一次无人任务。假设在启动任务时，我们对 Europa 卫星的表面了解甚少。相对于发送一两台相对重要的机器，发送“一群”罗德尼·布鲁克斯昆虫型机器人有什么优势？

可以协同工作，共同探索Europa卫星的表面，这种群体行为可以提高任务的效率和成功率。这些小型机器人可以更容易地穿越复杂的地形和环境，收集更多的数据。



13.Eliza 应该被视为一种关系型人造物吗？请给出是或不是的理由。

Eliza 是一种计算机程序，用来模拟人类对话。从定义上来看确实与人类有一定的关系，我个人觉得是的。



14.请听 The Killers 乐团的歌曲 Human，其中的歌词“Are We Human or Are We Dancer”是什么含义？它们与我们学习的课程有什么相关性？关于这一点，大家可以参与在线的热烈讨论（这首歌曲可以在 YouTube 上找到）

含义是我们是被命运或环境所驱使的舞者，还是能够自主选择和塑造自己的命运的人。

我们是被动地接受知识还是积极主动地探索和应用所学的知识，有点像人工智能的规则写死还是启发式学习。



15.人工智能问题与其他类型的问题有什么不同？列举常用的 5 种用于人工智能的问题解决技巧。

人工智能问题与其他类型的问题不同之处在于：

- 复杂性：人工智能问题通常具有高度的复杂性和不确定性，需要处理大量的数据和变量。

- 模糊性：人工智能问题往往涉及到模糊、不完整或不确定的信息，需要处理模糊逻辑和概率推理。

- 自动化：人工智能问题需要能够自动地从数据中学习和提取模式，而不需要显式的编程。

- 实时性：人工智能问题通常需要在实时环境中进行决策和响应，需要具备高效的计算和响应能力。

- 可解释性：人工智能问题需要能够解释其决策和推理过程，以便人类理解和信任。

常用的5种用于人工智能的问题解决技巧包括：

- 机器学习：通过训练模型来从数据中学习模式和规律，以进行预测和决策。

- 深度学习：利用深度神经网络模型来处理复杂的非线性关系和大规模数据。

- 自然语言处理：用于处理和理解人类语言的技术，包括文本分析、语音识别和机器翻译等。

- 计算机视觉：用于处理和理解图像和视频的技术，包括目标检测、图像分类和人脸识别等。

- 强化学习：通过试错和反馈机制来优化决策策略，以达到最大化长期奖励的目标。



16.请为人工智能设计一个新的适用于今天的图灵测试方法。

设计可以考虑以下要素：

- 多模态交互：将图灵测试扩展到包括多种感知模态，如视觉、听觉和自然语言等，这样可以让测试更加全面地评估人工智能系统的能力。

- 真实场景模拟：在测试中引入真实的场景和情境，以更贴近实际应用场景。例如，让参与者与人工智能系统进行实时对话，并要求他们解决实际问题或做出决策。

- 社交互动：考虑将社交互动纳入测试中，以评估人工智能系统在人际关系和情感交流方面的能力。这可以包括对情感的识别、表达和回应等。

- 个性化交互：允许参与者与人工智能系统进行个性化的交互，以便更好地评估其适应性和个性化能力。例如，根据参与者的兴趣、偏好和需求提供定制化的回答和建议。

- 伦理和社会影响评估：除了技术能力评估外，还应该考虑人工智能系统的伦理和社会影响。可以在测试中引入一些涉及伦理和社会问题的情境，以评估系统在这些方面的处理能力。



17.研究一下 Lovelace 2 机器人测试。大家觉得这个图灵机器人的新测试标准是否可以接受？如何对其与习题 2 的解答进行比较？

这个测试标准全面地评估了机器人的能力，并且更加注重对话的连贯性和上下文的理解，可以更好地反映机器人在实际使用中的智能水平，有助于提高机器人的用户体验和实用性。与习题2解答相比有着不同的初始设计思想和不同的实际场景应用。



## 思考题
![在这里插入图片描述](https://img-blog.csdnimg.cn/direct/850448520bca421984e02b0ace3c90cf.png)



1.学习、推理、决策、感知、理解和交互这些方面



2.人工智能是一种模拟人类智能的技术和系统，通过利用计算机和算法等工具，使机器能够感知、理解、学习和适应环境，并具备推理、决策、解决问题和交互等能力。它的目标是使机器能够像人类一样思考、学习和行动，以解决复杂的问题和完成各种任务。



3.合理，至于中文对话者的中文知识存在哪里，这个问题涉及到神经科学和认知科学的知识，目前科学好像还没无法完全解答这个问题



4.组合爆炸最大的挑战就是计算复杂性。可以通过知识表示和推理来减少问题的复杂性，将问题分解为更小的子问题，并将这些子问题的解决方案组合起来，能够降低问题的复杂性并提高求解效率。比如应用在专家系统和知识图谱等领域。



5.避免碰撞，跟随领头鸟，对齐飞行方向，调整速度，随机扰动



6.【一维元胞自动机】现考虑这样的一个一维元胞自动机：每个元胞的下一个状态只取决于其本身和左边、右边各一个的元胞状态。可以计算，一个完整的更新规则需要8条单独的转换规则（如 xox -> x )，请计算这样的一维元胞自动机的所有可能得更新规则数量。在 netlogo 在线网站仿真模拟这些规则，是否可以将这些规则分成若干种类？每一类的特征是什么？是否存在一个量与每个更新规则对应，取值正好可以将这几类分开？

所有可能的更新规则总共有256种，这些规则可以按照输出结果进行分类，每一种输出结果对应一种规则。例如Wolfram在研究这些元胞自动机时，将每种输入条件的输出0或1排列看成一个8位2进制数，并进行了标号。理论上可以通过某种量来将这些规则进行分类，但是这个量需要能够清晰地区分出不同的更新规则，且取值范围需要能够覆盖所有可能的规则数量，也许以后会有吧。



7．TLU可以处理线性分类问题，但是它不能直接完成异或（XOR）计算，异或操作涉及到非线性变换，而TLU的操作是线性的。解决方案：可能需要使用至少一个非线性激活函数或者构造一个非线性的系统。



8．现代人工智能大多基于大量的训练数据。你认为数据等于一切吗？为什么？

炼过丹的大家都知道足够的高质量数据是训练一个有效的人工智能模型的关键，但不是所有的数据都是有用的，比如说包含大量的噪声或者错误就会误导机器学习算法，导致模型的性能下降。在数据质量很高的情况下，如果没有合适的算法来处理这些数据，那么这些数据也无法发挥出它们的价值。而且过度依赖数据也可能导致一些问题，比如过拟合。我记得Datawhale在数据挖掘比赛上也分享过对数据处理的相关经验。



9.【零形回指】零形回指是指不显性使用代词，而以空位指代上文中出现过的名词性成分。考虑下面一则买包子的"程序员笑话"，你认为如果语言模型是否应该完美的建模一种自然语言？

语言模型的目标是尽可能地模拟和理解人类的语言，包括其复杂性、歧义性和多样性。从理论上来说语言模型应该能够完美地建模一种自然语言。但理想很丰满，现实大家懂得都懂。自然语言非常复杂包含了各种各样的语法结构、词汇选择和语境依赖性，人类的语言使用又是灵活多变的，同一句话在不同的语境中甚至不同人心中有不同的含义，我觉得没有必要完美建模一种。
